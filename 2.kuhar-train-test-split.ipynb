{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35c99f7-835d-4d62-b743-b80b81371bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "from typing import List\n",
    "from librep.actions.train import plot_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369d472c-0945-484e-a5be-c13cfdfeb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_names = {\n",
    "    0: \"Stand\",\n",
    "    1: \"Sit\",\n",
    "    2: \"Talk-sit\",\n",
    "    3: \"Talk-stand\",\n",
    "    4: \"Stand-sit\",\n",
    "    5: \"Lay\",\n",
    "    6: \"Lay-stand\",\n",
    "    7: \"Pick\",\n",
    "    8: \"Jump\",\n",
    "    9: \"Push-up\",\n",
    "    10: \"Sit-up\",\n",
    "    11: \"Walk\",\n",
    "    12: \"Walk-backwards\",\n",
    "    13: \"Walk-circle\",\n",
    "    14: \"Run\",\n",
    "    15: \"Stair-up\",\n",
    "    16: \"Stair-down\",\n",
    "    17: \"Table-tennis\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57785913-b2b8-4215-92bf-7bc177589018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_meta(directory, datafile=\"data.npz\", metafile=\"meta.csv\"):\n",
    "    data_fname = os.path.join(directory, datafile)\n",
    "    meta_fname = os.path.join(directory, metafile)\n",
    "    data = np.load(data_fname)[\"data\"]\n",
    "    meta = pd.read_csv(meta_fname)\n",
    "    return data, meta\n",
    "\n",
    "def train_val_test_split(df: pd.DataFrame, users: List[int], activities: List[int], train_size: float, validation_size: float, test_size: float):\n",
    "    retries = 10\n",
    "    n_users = len(users)\n",
    "    n_activities = len(activities)\n",
    "    \n",
    "    for i in range(retries):\n",
    "        shuffle(users)\n",
    "        # [start ---> train_size)\n",
    "        train_users = users[0:int(n_users*train_size)]\n",
    "        # [train_size --> train_size+validation_size)\n",
    "        validation_users = users[int(n_users*train_size) : int(n_users*(train_size+validation_size))]\n",
    "        # [train_size+validation_size --> end]\n",
    "        test_users = users[int(n_users*(train_size+validation_size)):]      \n",
    "        # iterate over user's lists, filter df for users in the respective list\n",
    "        all_sets = [df[df[\"user\"].isin(u)] for u in [train_users, validation_users, test_users]]\n",
    "        # We must guarantee that all sets contains at least 1 sample from each activities listed\n",
    "        oks = [set(s[\"class\"]) == set(activities) for s in all_sets]\n",
    "        if all(oks):\n",
    "            # If all sets contains at least 1 sample for each activity, return train, val, test sets!\n",
    "            return all_sets\n",
    "    print(f\"Does not found a 3 sets that contain the respective activities!\")\n",
    "    return [None, None, None]\n",
    "\n",
    "def balance(dataframe):\n",
    "    df_list = []\n",
    "    histogram = dataframe.groupby(dataframe[\"class\"], as_index=False).size()\n",
    "    for c in histogram[\"class\"]:\n",
    "        temp = dataframe.loc[dataframe[\"class\"] == c]\n",
    "        temp = temp.sample(n=histogram[\"size\"].min())\n",
    "        df_list.append(temp)\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def plot_meta_histogram(metadata):\n",
    "    histograms = metadata.groupby([\"class\"], as_index=False).size()\n",
    "    histograms[histograms[\"size\"] == histograms[\"size\"].min()]\n",
    "    plot_histogram(\n",
    "        histograms[\"size\"].to_dict(), labels_dict=activity_names,\n",
    "        minv=histograms[\"size\"].min(), maxv=histograms[\"size\"].max(),\n",
    "        min_max_v_xticks=1\n",
    "    )\n",
    "\n",
    "def select_from_meta(data, metadata):\n",
    "    arr = np.full((len(metadata), data.shape[1], data.shape[2]), fill_value=np.nan)\n",
    "    for i, npidx in enumerate(metadata[\"np_index\"]):\n",
    "        arr[i,:,:] = data[npidx]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56f7f0-3adb-4f89-b841-3ee76c9cca44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24305ca3-aa83-49db-9a2c-2abafca3912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Starting with data/dataset_views/kuhar/time-series-300-samples-0-overlap/all/486c8aad/ ----------\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/all/486c8aad/train.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/all/486c8aad/train.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/all/486c8aad/validation.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/all/486c8aad/validation.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/all/486c8aad/test.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/all/486c8aad/test.csv'\n",
      "---------- Starting with data/dataset_views/kuhar/time-series-300-samples-0-overlap/accelerometer/486c8aad ----------\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/accelerometer/486c8aad/train.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/accelerometer/486c8aad/train.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/accelerometer/486c8aad/validation.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/accelerometer/486c8aad/validation.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/accelerometer/486c8aad/test.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/accelerometer/486c8aad/test.csv'\n",
      "---------- Starting with data/dataset_views/kuhar/time-series-300-samples-0-overlap/gyroscope/486c8aad ----------\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/gyroscope/486c8aad/train.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/gyroscope/486c8aad/train.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/gyroscope/486c8aad/validation.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/gyroscope/486c8aad/validation.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/gyroscope/486c8aad/test.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/time-series-300-samples-0-overlap/gyroscope/486c8aad/test.csv'\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"data/dataset_views/kuhar/time-series-300-samples-0-overlap/all/486c8aad/\",\n",
    "    \"data/dataset_views/kuhar/time-series-300-samples-0-overlap/accelerometer/486c8aad\",\n",
    "    \"data/dataset_views/kuhar/time-series-300-samples-0-overlap/gyroscope/486c8aad\",\n",
    "]\n",
    "\n",
    "data, metadata = read_data_meta(paths[0])\n",
    "metadata[\"np_index\"] = range(len(metadata))\n",
    "users = sorted(metadata[\"user\"].unique().tolist())\n",
    "classes = sorted(metadata[\"class\"].unique().tolist())\n",
    "    \n",
    "train_meta, val_meta, test_meta = train_val_test_split(\n",
    "    df=metadata, users=users, activities=classes, train_size=0.7, \n",
    "    validation_size=0.1, test_size=0.2)\n",
    "\n",
    "train_meta = balance(train_meta)\n",
    "val_meta = balance(val_meta)\n",
    "test_meta = balance(test_meta)\n",
    "\n",
    "for path in paths:\n",
    "    print(f\"---------- Starting with {path} ----------\")\n",
    "    data, metadata = read_data_meta(path)\n",
    "    for s, set_name in [(train_meta, \"train\"), (val_meta, \"validation\"), (test_meta, \"test\")]:\n",
    "        arr = select_from_meta(data, s)\n",
    "        data_output = os.path.join(path, set_name)\n",
    "        meta_output = os.path.join(path, f\"{set_name}.csv\")\n",
    "        np.savez(data_output, data=arr)\n",
    "        print(f\"Data saved to '{data_output}.npz'\")\n",
    "        s.to_csv(meta_output, index=False)\n",
    "        print(f\"Metadata saved to '{meta_output}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "289e0935-81ac-444b-899e-0f257edd0b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Starting with data/dataset_views/kuhar/raw/all/486c8aad/ ----------\n",
      "Data saved to 'data/dataset_views/kuhar/raw/all/486c8aad/train.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/all/486c8aad/train.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/raw/all/486c8aad/validation.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/all/486c8aad/validation.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/raw/all/486c8aad/test.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/all/486c8aad/test.csv'\n",
      "---------- Starting with data/dataset_views/kuhar/raw/accelerometer/486c8aad ----------\n",
      "Data saved to 'data/dataset_views/kuhar/raw/accelerometer/486c8aad/train.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/accelerometer/486c8aad/train.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/raw/accelerometer/486c8aad/validation.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/accelerometer/486c8aad/validation.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/raw/accelerometer/486c8aad/test.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/accelerometer/486c8aad/test.csv'\n",
      "---------- Starting with data/dataset_views/kuhar/raw/gyroscope/486c8aad ----------\n",
      "Data saved to 'data/dataset_views/kuhar/raw/gyroscope/486c8aad/train.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/gyroscope/486c8aad/train.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/raw/gyroscope/486c8aad/validation.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/gyroscope/486c8aad/validation.csv'\n",
      "Data saved to 'data/dataset_views/kuhar/raw/gyroscope/486c8aad/test.npz'\n",
      "Metadata saved to 'data/dataset_views/kuhar/raw/gyroscope/486c8aad/test.csv'\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"data/dataset_views/kuhar/raw/all/486c8aad/\",\n",
    "    \"data/dataset_views/kuhar/raw/accelerometer/486c8aad\",\n",
    "    \"data/dataset_views/kuhar/raw/gyroscope/486c8aad\"\n",
    "]\n",
    "\n",
    "data, metadata = read_data_meta(paths[0])\n",
    "metadata[\"np_index\"] = range(len(metadata))\n",
    "users = sorted(metadata[\"user\"].unique().tolist())\n",
    "classes = sorted(metadata[\"class\"].unique().tolist())\n",
    "    \n",
    "train_meta, val_meta, test_meta = train_val_test_split(\n",
    "    df=metadata, users=users, activities=classes, train_size=0.7, \n",
    "    validation_size=0.1, test_size=0.2)\n",
    "\n",
    "train_meta = balance(train_meta)\n",
    "val_meta = balance(val_meta)\n",
    "test_meta = balance(test_meta)\n",
    "\n",
    "for path in paths:\n",
    "    print(f\"---------- Starting with {path} ----------\")\n",
    "    data, metadata = read_data_meta(path)\n",
    "    for s, set_name in [(train_meta, \"train\"), (val_meta, \"validation\"), (test_meta, \"test\")]:\n",
    "        arr = select_from_meta(data, s)\n",
    "        data_output = os.path.join(path, set_name)\n",
    "        meta_output = os.path.join(path, f\"{set_name}.csv\")\n",
    "        np.savez(data_output, data=arr)\n",
    "        print(f\"Data saved to '{data_output}.npz'\")\n",
    "        s.to_csv(meta_output, index=False)\n",
    "        print(f\"Metadata saved to '{meta_output}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc40a6d-0553-4828-ae47-679a8c14c19c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
